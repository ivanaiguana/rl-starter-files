{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwsKJPT6D8hFBxQuvREX9w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivanaiguana/rl-starter-files/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj4RJey96Wu4"
      },
      "outputs": [],
      "source": [
        "!pip install pdfplumber transformers sentencepiece peft accelerate nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "Cw2IXlz96m7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def extract_pdf_text(file_path):\n",
        "    full_text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                full_text += page_text + \"\\n\"\n",
        "    return full_text\n",
        "\n",
        "pdf_text = extract_pdf_text(\"2.pdf\")\n",
        "print(pdf_text[:1000])  # Preview first 1000 characters\n"
      ],
      "metadata": {
        "id": "lCVSpoYi66qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def split_sections(text):\n",
        "    sections = {}\n",
        "    chunks = re.split(r'\\n(?=\\d+\\.\\s+)', text)\n",
        "    for chunk in chunks:\n",
        "        lines = chunk.strip().split(\"\\n\")\n",
        "        if lines:\n",
        "            title = lines[0].strip()\n",
        "            content = \"\\n\".join(lines[1:]).strip()\n",
        "            sections[title] = content\n",
        "    return sections\n",
        "\n",
        "sections = split_sections(pdf_text)\n",
        "for title, content in sections.items():\n",
        "    print(f\"\\n=== {title} ===\\n{content[:300]}...\")\n"
      ],
      "metadata": {
        "id": "ydPkEhGz7EHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "v-3QquWF7VeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def summarize_text(text, max_length=150):\n",
        "    input_text = \"Summarize: \" + text\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
        "    outputs = model.generate(inputs.input_ids, max_length=max_length)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "summaries = {}\n",
        "for title, content in sections.items():\n",
        "    print(f\"Summarizing: {title}\")\n",
        "    summary = summarize_text(content)\n",
        "    summaries[title] = summary\n",
        "    print(f\"â†’ {summary}\\n\")\n"
      ],
      "metadata": {
        "id": "sXVNtMyg7cpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(summaries, indent=2))\n"
      ],
      "metadata": {
        "id": "aQnMJBvZ7d2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"summary_output.json\", \"w\") as f:\n",
        "    json.dump(summaries, f, indent=2)\n",
        "files.download(\"summary_output.json\")\n"
      ],
      "metadata": {
        "id": "9z3yQ7TW7jBf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}